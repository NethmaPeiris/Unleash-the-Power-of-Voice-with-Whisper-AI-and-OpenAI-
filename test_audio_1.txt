I'm interested and I think everybody is interested in the three laws of robotics. Could you explain those?
Well, back in 1939, I began writing robot stories. And by the time I'd written two and three, there was a pattern in these stories which John Campbell, the editor of Astounding Science Fiction and my literary father, pointed out to me.
He said, I was having my robots behave as though they were guided by three laws.
The first law was that a robot couldn't hurt a human being or through inaction allow a human being to come to harm.
The second law was that a robot had to obey orders given it by human beings provided that didn't conflict with the first law.
And the third law was that a robot had to protect its own existence except where that would conflict with the first two laws.
And after that, I always used them and the stories evolved out of those three laws, out of the mutual contradictions, out of the ambivalences, the incongruities and so on.
The interesting thing is that scientists say that when robots are built that they may be built according to these laws and also that almost all science fiction writers have adopted them as well in their stories.
That's true about the science fiction writers adopting them. They are not taken for granted. No writer actually quotes them except myself.
But the readers are so used to it now that they know it and they take it for granted.
And somebody writing in an architectural journal pointed out that these laws hold for tools generally.
Number one, a tool must be safe to use. And two, provided it is safe to use, it's got to do what you want it to do.
And third, provided it is safe to use and it does what you want to, it's got to last.
But could your three laws of robotics be overloaded on the side of humanism?
There are those who believe that the machines we create are going to be Frankenstein's.
Well, of course, the three laws of robotics were originally invented by me in order to avoid the Frankenstein motive.
Because before I wrote my stories, most robot stories were filled with this Frankenstein bit about the robot destroying its creator.
There are some things that men were not meant to know.
However, having worked with the three laws for now for 35 years, practically, I was asked to write a robot story to end all robot stories.
So I wrote one in which robots became so intelligent that by any reasonable definition, they define themselves as human beings, you see.
So that now the three laws of robotics became the three laws of humanics.
And we were right back to the Frankenstein motif.
I received letters from readers saying, does this mean you're never going to write any more robot stories?
And I wrote back saying, don't worry, if I think of a good robot story, I'll write it anyway.
You know, I'm not a robot.
I'm a robot.
I'm a robot.
I'm a robot.
I'm a robot.
I'm a robot.
I'm a robot.
I'm a robot.
I'm a robot.
I'm a robot.
I'm a robot.
I'm a robot.
I'm a robot.
I'm a robot.
